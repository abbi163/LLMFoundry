{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning with Trae AI\n",
    "\n",
    "This notebook demonstrates how to fine-tune language models using Trae AI's advanced training capabilities.\n",
    "\n",
    "## Learning Objectives\n",
    "- Prepare datasets for fine-tuning\n",
    "- Configure Trae AI training parameters\n",
    "- Monitor training progress\n",
    "- Evaluate fine-tuned models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import our custom modules\n",
    "from trae_llm.config import load_config\n",
    "from trae_llm.dataset import prepare_dataset\n",
    "from trae_llm.trainer import TraeTrainer\n",
    "\n",
    "print(\"Environment setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "First, let's prepare a dataset for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset for demonstration\n",
    "sample_data = [\n",
    "    {\n",
    "        \"instruction\": \"Explain the concept of machine learning\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. It uses algorithms to analyze data, identify patterns, and make predictions or decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Write a Python function to calculate factorial\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"def factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n - 1)\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Summarize the benefits of renewable energy\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"Renewable energy offers numerous benefits including reduced greenhouse gas emissions, energy independence, job creation, and long-term cost savings. It helps combat climate change while providing sustainable power sources.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Translate the following to French\",\n",
    "        \"input\": \"Hello, how are you?\",\n",
    "        \"output\": \"Bonjour, comment allez-vous?\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Explain quantum computing in simple terms\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"Quantum computing uses quantum mechanical phenomena like superposition and entanglement to process information. Unlike classical computers that use bits (0 or 1), quantum computers use quantum bits (qubits) that can exist in multiple states simultaneously, potentially solving certain problems much faster.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create more samples by duplicating and modifying\n",
    "extended_data = []\n",
    "for i in range(20):  # Create 100 samples\n",
    "    for item in sample_data:\n",
    "        extended_data.append(item.copy())\n",
    "\n",
    "print(f\"Created {len(extended_data)} training samples\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(extended_data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data for instruction tuning\n",
    "def format_instruction(sample):\n",
    "    \"\"\"Format sample for instruction tuning\"\"\"\n",
    "    if sample['input'].strip():\n",
    "        return f\"### Instruction:\\n{sample['instruction']}\\n\\n### Input:\\n{sample['input']}\\n\\n### Response:\\n{sample['output']}\"\n",
    "    else:\n",
    "        return f\"### Instruction:\\n{sample['instruction']}\\n\\n### Response:\\n{sample['output']}\"\n",
    "\n",
    "# Apply formatting\n",
    "df['text'] = df.apply(format_instruction, axis=1)\n",
    "\n",
    "# Show formatted example\n",
    "print(\"Formatted training example:\")\n",
    "print(\"=\" * 50)\n",
    "print(df['text'].iloc[0])\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Split into train/validation\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:]\n",
    "\n",
    "# Save as JSONL\n",
    "train_file = data_dir / 'train.jsonl'\n",
    "val_file = data_dir / 'val.jsonl'\n",
    "\n",
    "train_df.to_json(train_file, orient='records', lines=True)\n",
    "val_df.to_json(val_file, orient='records', lines=True)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(train_df)} training samples to {train_file}\")\n",
    "print(f\"‚úÖ Saved {len(val_df)} validation samples to {val_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model and Tokenizer Setup\n",
    "\n",
    "Load the base model and tokenizer for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"microsoft/DialoGPT-small\"  # Using a smaller model for demo\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Add padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model.num_parameters():,} parameters\")\n",
    "print(f\"‚úÖ Tokenizer vocabulary size: {len(tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the text data\"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # For causal LM, labels are the same as input_ids\n",
    "    tokenized['labels'] = tokenized['input_ids'].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Load and tokenize datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Apply tokenization\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"‚úÖ Validation dataset: {len(val_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "Set up training parameters optimized for Trae AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "output_dir = Path('../checkpoints/fine_tuned_model')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(output_dir),\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    \n",
    "    # Logging and evaluation\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    # Performance\n",
    "    dataloader_num_workers=0,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    \n",
    "    # Misc\n",
    "    report_to=None,  # Disable wandb for demo\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Output directory: {training_args.output_dir}\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  FP16: {training_args.fp16}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're doing causal LM, not masked LM\n",
    "    pad_to_multiple_of=8 if training_args.fp16 else None,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trae AI Enhanced Training\n",
    "\n",
    "Use Trae AI's optimized trainer for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom trainer with Trae AI optimizations\n",
    "class TraeOptimizedTrainer(Trainer):\n",
    "    \"\"\"Enhanced trainer with Trae AI optimizations\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.trae_metrics = []\n",
    "    \n",
    "    def log(self, logs):\n",
    "        \"\"\"Enhanced logging with Trae AI metrics\"\"\"\n",
    "        super().log(logs)\n",
    "        \n",
    "        # Add Trae AI specific metrics\n",
    "        if 'train_loss' in logs:\n",
    "            trae_metrics = {\n",
    "                'step': self.state.global_step,\n",
    "                'train_loss': logs['train_loss'],\n",
    "                'learning_rate': logs.get('learning_rate', 0),\n",
    "                'memory_usage': self._get_memory_usage(),\n",
    "                'throughput': self._calculate_throughput()\n",
    "            }\n",
    "            self.trae_metrics.append(trae_metrics)\n",
    "    \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Get current memory usage\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.cuda.memory_allocated() / 1024**3  # GB\n",
    "        return 0\n",
    "    \n",
    "    def _calculate_throughput(self):\n",
    "        \"\"\"Calculate training throughput\"\"\"\n",
    "        # Simplified throughput calculation\n",
    "        if hasattr(self.state, 'log_history') and len(self.state.log_history) > 1:\n",
    "            return len(self.train_dataset) / (self.state.global_step + 1)\n",
    "        return 0\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = TraeOptimizedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trae AI optimized trainer initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Execution\n",
    "\n",
    "Start the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training evaluation\n",
    "print(\"Evaluating model before training...\")\n",
    "pre_train_metrics = trainer.evaluate()\n",
    "print(f\"Pre-training loss: {pre_train_metrics['eval_loss']:.4f}\")\n",
    "\n",
    "# Start training\n",
    "print(\"\nüöÄ Starting fine-tuning with Trae AI optimizations...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    print(\"\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    # For demo purposes, we'll continue with the pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-training evaluation\n",
    "print(\"Evaluating model after training...\")\n",
    "post_train_metrics = trainer.evaluate()\n",
    "print(f\"Post-training loss: {post_train_metrics['eval_loss']:.4f}\")\n",
    "\n",
    "# Compare metrics\n",
    "improvement = pre_train_metrics['eval_loss'] - post_train_metrics['eval_loss']\n",
    "print(f\"\nImprovement: {improvement:.4f} ({improvement/pre_train_metrics['eval_loss']*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Testing\n",
    "\n",
    "Test the fine-tuned model with sample prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tokenizer, prompt, max_length=100):\n",
    "    \"\"\"Test the fine-tuned model\"\"\"\n",
    "    # Format prompt in instruction format\n",
    "    formatted_prompt = f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer.encode(formatted_prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=inputs.shape[1] + max_length,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode response\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text[len(formatted_prompt):].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"Explain what deep learning is\",\n",
    "    \"Write a Python function to reverse a string\",\n",
    "    \"What are the benefits of cloud computing?\",\n",
    "    \"Describe the process of photosynthesis\"\n",
    "]\n",
    "\n",
    "print(\"Testing fine-tuned model:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"Test {i}: {prompt}\")\n",
    "    response = test_model(model, tokenizer, prompt)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Saving and Export\n",
    "\n",
    "Save the fine-tuned model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model_save_path = Path('../models/fine_tuned_model')\n",
    "model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to {model_save_path}\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics_file = model_save_path / 'training_metrics.json'\n",
    "training_metrics = {\n",
    "    'pre_train_loss': pre_train_metrics['eval_loss'],\n",
    "    'post_train_loss': post_train_metrics['eval_loss'],\n",
    "    'improvement': improvement,\n",
    "    'training_args': training_args.to_dict(),\n",
    "    'trae_metrics': trainer.trae_metrics[-5:] if trainer.trae_metrics else []\n",
    "}\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(training_metrics, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Training metrics saved to {metrics_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis\n",
    "\n",
    "Analyze the training performance and Trae AI optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training metrics if available\n",
    "if trainer.trae_metrics:\n",
    "    metrics_df = pd.DataFrame(trainer.trae_metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Training loss\n",
    "    axes[0, 0].plot(metrics_df['step'], metrics_df['train_loss'])\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].set_xlabel('Step')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[0, 1].plot(metrics_df['step'], metrics_df['learning_rate'])\n",
    "    axes[0, 1].set_title('Learning Rate')\n",
    "    axes[0, 1].set_xlabel('Step')\n",
    "    axes[0, 1].set_ylabel('LR')\n",
    "    \n",
    "    # Memory usage\n",
    "    axes[1, 0].plot(metrics_df['step'], metrics_df['memory_usage'])\n",
    "    axes[1, 0].set_title('Memory Usage (GB)')\n",
    "    axes[1, 0].set_xlabel('Step')\n",
    "    axes[1, 0].set_ylabel('Memory (GB)')\n",
    "    \n",
    "    # Throughput\n",
    "    axes[1, 1].plot(metrics_df['step'], metrics_df['throughput'])\n",
    "    axes[1, 1].set_title('Training Throughput')\n",
    "    axes[1, 1].set_xlabel('Step')\n",
    "    axes[1, 1].set_ylabel('Samples/Step')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(model_save_path / 'training_metrics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Training metrics visualization saved\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training metrics available for visualization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! You've successfully fine-tuned a model with Trae AI. Continue with:\n",
    "\n",
    "- **04_rag_with_trae.ipynb**: Build RAG systems with your fine-tuned model\n",
    "- **05_evaluation_and_visualization.ipynb**: Comprehensive model evaluation\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Data Preparation**: Proper formatting is crucial for instruction tuning\n",
    "2. **Trae AI Optimizations**: Enhanced trainer provides better performance monitoring\n",
    "3. **Training Configuration**: Balanced parameters for efficient training\n",
    "4. **Model Testing**: Always validate your fine-tuned model with diverse prompts\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Try these advanced exercises:\n",
    "\n",
    "1. Experiment with different learning rates and batch sizes\n",
    "2. Add more diverse training data\n",
    "3. Implement custom evaluation metrics\n",
    "4. Try different model architectures (Llama, Mistral, etc.)\n",
    "5. Implement LoRA (Low-Rank Adaptation) for efficient fine-tuning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}